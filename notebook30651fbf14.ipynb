{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6447a2e7",
   "metadata": {},
   "source": [
    "# Fine-tune Intent Classification Model\n",
    "## Customer Service Chatbot - Intent Classifier Training\n",
    "\n",
    "This notebook fine-tunes a DistilBERT model for intent classification.\n",
    "\n",
    "**Platform:** Google Colab or Kaggle\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Load training data\n",
    "3. Prepare dataset\n",
    "4. Fine-tune DistilBERT\n",
    "5. Evaluate and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f14873-03a7-473c-8507-04ca5b3292c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:11.417477Z",
     "iopub.status.busy": "2026-01-28T08:03:11.416782Z",
     "iopub.status.idle": "2026-01-28T08:03:11.424387Z",
     "shell.execute_reply": "2026-01-28T08:03:11.423758Z",
     "shell.execute_reply.started": "2026-01-28T08:03:11.417449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fix tokenizer parallelism issue\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5bf922",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84463eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:11.426195Z",
     "iopub.status.busy": "2026-01-28T08:03:11.425894Z",
     "iopub.status.idle": "2026-01-28T08:03:15.817182Z",
     "shell.execute_reply": "2026-01-28T08:03:15.816231Z",
     "shell.execute_reply.started": "2026-01-28T08:03:11.426173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch scikit-learn accelerate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ad4d8",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5762b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:15.818812Z",
     "iopub.status.busy": "2026-01-28T08:03:15.818546Z",
     "iopub.status.idle": "2026-01-28T08:03:46.507763Z",
     "shell.execute_reply": "2026-01-28T08:03:46.506971Z",
     "shell.execute_reply.started": "2026-01-28T08:03:15.818784Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 08:03:31.480291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769587411.677662      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769587411.737919      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769587412.242769      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769587412.242809      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769587412.242811      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769587412.242814      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebb91f",
   "metadata": {},
   "source": [
    "## 3. Load Training Data\n",
    "\n",
    "**Choose one of the options below:**\n",
    "\n",
    "**Option 1:** Use SNIPS Intent Dataset (7 intents, 2,4K examples) - **Recommended for intent classification**\n",
    "\n",
    "**Option 2:** Upload your own train_data.json and val_data.json (1,315 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51f2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:46.509815Z",
     "iopub.status.busy": "2026-01-28T08:03:46.508790Z",
     "iopub.status.idle": "2026-01-28T08:03:46.548716Z",
     "shell.execute_reply": "2026-01-28T08:03:46.547945Z",
     "shell.execute_reply.started": "2026-01-28T08:03:46.509786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 1315\n",
      "Validation examples: 329\n",
      "\n",
      "Sample: {'text': 'i want exit', 'label': 'goodbye'}\n"
     ]
    }
   ],
   "source": [
    "# OPTION 1: Use SNIPS Intent Dataset (recommended)\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"üì• Loading SNIPS Built-in Intents dataset...\")\n",
    "dataset = load_dataset(\"snips_built_in_intents\")\n",
    "\n",
    "# Convert to our format\n",
    "train_data = [\n",
    "    {\"text\": item[\"text\"], \"label\": dataset[\"train\"].features[\"label\"].int2str(item[\"label\"])} \n",
    "    for item in dataset[\"train\"]\n",
    "]\n",
    "val_data = [\n",
    "    {\"text\": item[\"text\"], \"label\": dataset[\"test\"].features[\"label\"].int2str(item[\"label\"])} \n",
    "    for item in dataset[\"test\"]\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Training examples: {len(train_data)}\")\n",
    "print(f\"‚úÖ Validation examples: {len(val_data)}\")\n",
    "print(f\"\\nüìù Sample: {train_data[0]}\")\n",
    "\n",
    "# Show all intents\n",
    "unique_labels = sorted(list(set([item['label'] for item in train_data])))\n",
    "print(f\"\\nüìä Number of intents: {len(unique_labels)}\")\n",
    "print(f\"Intents: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f60852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: Upload your own files (comment out SNIPS above first)\n",
    "# import json\n",
    "# with open('/kaggle/input/customer-chatbot/train_data.json', 'r') as f:\n",
    "#     train_data = json.load(f)\n",
    "# with open('/kaggle/input/customer-chatbot/val_data.json', 'r') as f:\n",
    "#     val_data = json.load(f)\n",
    "# print(f\"‚úÖ Training examples: {len(train_data)}\")\n",
    "# print(f\"‚úÖ Validation examples: {len(val_data)}\")\n",
    "# unique_labels = sorted(list(set([item['label'] for item in train_data])))\n",
    "# print(f\"\\nüìä Number of intents: {len(unique_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc2a4b",
   "metadata": {},
   "source": [
    "### Option 2: Upload Your Own Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b0c2e3",
   "metadata": {},
   "source": [
    "## 4. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526b1fcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:46.550717Z",
     "iopub.status.busy": "2026-01-28T08:03:46.550437Z",
     "iopub.status.idle": "2026-01-28T08:03:46.570312Z",
     "shell.execute_reply": "2026-01-28T08:03:46.569624Z",
     "shell.execute_reply.started": "2026-01-28T08:03:46.550695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of intents: 10\n",
      "Labels: ['goodbye', 'greeting', 'hours', 'order_status', 'payment', 'pricing', 'product_info', 'return', 'support', 'thanks']\n",
      "\n",
      "Dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create label mapping\n",
    "unique_labels = sorted(list(set([item['label'] for item in train_data])))\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Number of intents: {len(unique_labels)}\")\n",
    "print(f\"Labels: {unique_labels}\")\n",
    "\n",
    "# Convert labels to IDs\n",
    "for item in train_data:\n",
    "    item['labels'] = label2id[item['label']]\n",
    "\n",
    "for item in val_data:\n",
    "    item['labels'] = label2id[item['label']]\n",
    "\n",
    "# Create Hugging Face datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "\n",
    "print(f\"\\nDataset created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c87a1",
   "metadata": {},
   "source": [
    "## 5. Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9df5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:46.571431Z",
     "iopub.status.busy": "2026-01-28T08:03:46.571189Z",
     "iopub.status.idle": "2026-01-28T08:03:49.718433Z",
     "shell.execute_reply": "2026-01-28T08:03:49.717705Z",
     "shell.execute_reply.started": "2026-01-28T08:03:46.571409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8366f15ad942a5a213411947f56aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b550438969d4679ad229fc8988f8e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59d3e9731a8497e9d3e7f0088f14695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e4630762884d1d9a9c7bcc0f9010d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22100d4f86fb4f2b9cd50247be800cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1315 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287d21a496104c6bb6e86cedefd1798c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/329 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove unnecessary columns - keep only what the model needs\n",
    "tokenized_train = tokenized_train.remove_columns(['text', 'label'])\n",
    "tokenized_val = tokenized_val.remove_columns(['text', 'label'])\n",
    "\n",
    "print(\"‚úÖ Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d045063",
   "metadata": {},
   "source": [
    "## 6. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c0de5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:49.719734Z",
     "iopub.status.busy": "2026-01-28T08:03:49.719461Z",
     "iopub.status.idle": "2026-01-28T08:03:53.732136Z",
     "shell.execute_reply": "2026-01-28T08:03:53.731305Z",
     "shell.execute_reply.started": "2026-01-28T08:03:49.719711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155167f743c04a67a146ac49bb5a0e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded: distilbert-base-uncased\n",
      "üìä Parameters: 66,961,162\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "print(f\"üìä Parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e2ef5",
   "metadata": {},
   "source": [
    "## 7. Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9f9112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:53.733307Z",
     "iopub.status.busy": "2026-01-28T08:03:53.733069Z",
     "iopub.status.idle": "2026-01-28T08:03:53.737783Z",
     "shell.execute_reply": "2026-01-28T08:03:53.737083Z",
     "shell.execute_reply.started": "2026-01-28T08:03:53.733284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f55cfa",
   "metadata": {},
   "source": [
    "## 8. Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef158b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:53.739045Z",
     "iopub.status.busy": "2026-01-28T08:03:53.738746Z",
     "iopub.status.idle": "2026-01-28T08:03:54.057809Z",
     "shell.execute_reply": "2026-01-28T08:03:54.057248Z",
     "shell.execute_reply.started": "2026-01-28T08:03:53.738994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./intent_classifier\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    logging_steps=10,\n",
    "    warmup_steps=100,\n",
    "    dataloader_num_workers=0,\n",
    "    report_to=\"none\",                    # ADD THIS LINE - disables wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33005cfa-d03a-41a8-8785-02f63e274449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:54.059001Z",
     "iopub.status.busy": "2026-01-28T08:03:54.058698Z",
     "iopub.status.idle": "2026-01-28T08:03:54.112386Z",
     "shell.execute_reply": "2026-01-28T08:03:54.111475Z",
     "shell.execute_reply.started": "2026-01-28T08:03:54.058970Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 28 08:03:54 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0             31W /  250W |     257MiB /  16384MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check GPU memory before training\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20ff3d",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189b42ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:03:54.113793Z",
     "iopub.status.busy": "2026-01-28T08:03:54.113354Z",
     "iopub.status.idle": "2026-01-28T08:04:08.787515Z",
     "shell.execute_reply": "2026-01-28T08:04:08.786756Z",
     "shell.execute_reply.started": "2026-01-28T08:03:54.113758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "Training samples: 1315\n",
      "Validation samples: 329\n",
      "Starting epoch 1 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/3793347754.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 00:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.073600</td>\n",
       "      <td>0.760674</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.932007</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.945001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.057082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create trainer with more verbosity\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train with progress tracking\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(f\"Training samples: {len(tokenized_train)}\")\n",
    "print(f\"Validation samples: {len(tokenized_val)}\")\n",
    "print(f\"Starting epoch 1 of {training_args.num_train_epochs}...\")\n",
    "\n",
    "trainer.train()\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104426d",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4e2a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:04:08.788674Z",
     "iopub.status.busy": "2026-01-28T08:04:08.788387Z",
     "iopub.status.idle": "2026-01-28T08:04:09.025031Z",
     "shell.execute_reply": "2026-01-28T08:04:09.024380Z",
     "shell.execute_reply.started": "2026-01-28T08:04:08.788646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluation Results:\n",
      "  eval_loss: 0.0571\n",
      "  eval_accuracy: 1.0000\n",
      "  eval_precision: 1.0000\n",
      "  eval_recall: 1.0000\n",
      "  eval_f1: 1.0000\n",
      "  eval_runtime: 0.2281\n",
      "  eval_samples_per_second: 1442.1900\n",
      "  eval_steps_per_second: 184.1090\n",
      "  epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nüìä Evaluation Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b114a",
   "metadata": {},
   "source": [
    "## 11. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c3bd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:04:09.026298Z",
     "iopub.status.busy": "2026-01-28T08:04:09.025818Z",
     "iopub.status.idle": "2026-01-28T08:04:09.066700Z",
     "shell.execute_reply": "2026-01-28T08:04:09.065969Z",
     "shell.execute_reply.started": "2026-01-28T08:04:09.026275Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing predictions:\n",
      "\n",
      "Text: 'Hello, how are you?'\n",
      "  ‚Üí Intent: greeting (confidence: 94.22%)\n",
      "\n",
      "Text: 'Where is my package?'\n",
      "  ‚Üí Intent: order_status (confidence: 95.27%)\n",
      "\n",
      "Text: 'How much does this cost?'\n",
      "  ‚Üí Intent: pricing (confidence: 94.89%)\n",
      "\n",
      "Text: 'I want to return my order'\n",
      "  ‚Üí Intent: order_status (confidence: 81.71%)\n",
      "\n",
      "Text: 'What products do you have?'\n",
      "  ‚Üí Intent: product_info (confidence: 94.93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "def predict_intent(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_class_id = predictions.argmax().item()\n",
    "    confidence = predictions[0][predicted_class_id].item()\n",
    "    \n",
    "    return id2label[predicted_class_id], confidence\n",
    "\n",
    "# Test examples\n",
    "test_examples = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Where is my package?\",\n",
    "    \"How much does this cost?\",\n",
    "    \"I want to return my order\",\n",
    "    \"What products do you have?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing predictions:\\n\")\n",
    "for example in test_examples:\n",
    "    intent, confidence = predict_intent(example)\n",
    "    print(f\"Text: '{example}'\")\n",
    "    print(f\"  ‚Üí Intent: {intent} (confidence: {confidence:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385aa67e",
   "metadata": {},
   "source": [
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d50fe06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:07:43.903667Z",
     "iopub.status.busy": "2026-01-28T08:07:43.902766Z",
     "iopub.status.idle": "2026-01-28T08:07:57.323741Z",
     "shell.execute_reply": "2026-01-28T08:07:57.323059Z",
     "shell.execute_reply.started": "2026-01-28T08:07:43.903630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model zipped successfully: intent_classifier_final_20260128_080743.zip\n",
      "üì¶ Size: 235.88 MB\n",
      "\n",
      "üì• To download from Kaggle:\n",
      "   1. Click 'Output' tab in the right sidebar\n",
      "   2. Look for 'intent_classifier_final_20260128_080743.zip'\n",
      "   3. Click download icon\n",
      "\n",
      "üí° After download, extract to:\n",
      "   d:\\3224\\customer-service-chatbot\\models\\intent_classifier_final\\\n"
     ]
    }
   ],
   "source": [
    "# Create a zip file of the trained model for download\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure we're in the working directory where Kaggle can find outputs\n",
    "os.chdir('/kaggle/working')\n",
    "\n",
    "# Create zip file with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_filename = f\"intent_classifier_final_{timestamp}\"\n",
    "shutil.make_archive(zip_filename, 'zip', output_dir)\n",
    "\n",
    "# Verify the file exists\n",
    "zip_path = f\"{zip_filename}.zip\"\n",
    "if os.path.exists(zip_path):\n",
    "    size_mb = os.path.getsize(zip_path) / (1024*1024)\n",
    "    print(f\"‚úÖ Model zipped successfully: {zip_filename}.zip\")\n",
    "    print(f\"üì¶ Size: {size_mb:.2f} MB\")\n",
    "    print(f\"\\nüì• To download from Kaggle:\")\n",
    "    print(f\"   1. Click 'Output' tab in the right sidebar\")\n",
    "    print(f\"   2. Look for '{zip_filename}.zip'\")\n",
    "    print(f\"   3. Click download icon\")\n",
    "    print(f\"\\nüí° After download, extract to:\")\n",
    "    print(f\"   d:\\\\3224\\\\customer-service-chatbot\\\\models\\\\intent_classifier_final\\\\\")\n",
    "else:\n",
    "    print(\"‚ùå Error: Zip file not created. Check permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9bc7d1-3ba7-4b49-b92f-77cbb54cb88d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T08:07:57.325355Z",
     "iopub.status.busy": "2026-01-28T08:07:57.325049Z",
     "iopub.status.idle": "2026-01-28T08:07:57.331677Z",
     "shell.execute_reply": "2026-01-28T08:07:57.331086Z",
     "shell.execute_reply.started": "2026-01-28T08:07:57.325332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='intent_classifier_final_20260128_080743.zip' target='_blank'>intent_classifier_final_20260128_080743.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/intent_classifier_final_20260128_080743.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÜ Click the link above to download directly!\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Use Kaggle's download function\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Display clickable download link\n",
    "zip_path = f\"{zip_filename}.zip\"\n",
    "display(FileLink(zip_path))\n",
    "print(f\"üëÜ Click the link above to download directly!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9355971,
     "sourceId": 14646161,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
