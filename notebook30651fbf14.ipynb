{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14646161,"sourceType":"datasetVersion","datasetId":9355971}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6447a2e7","cell_type":"markdown","source":"# Fine-tune Intent Classification Model\n## Customer Service Chatbot - Intent Classifier Training\n\nThis notebook fine-tunes a DistilBERT model for intent classification.\n\n**Platform:** Google Colab or Kaggle\n\n**Steps:**\n1. Install dependencies\n2. Load training data\n3. Prepare dataset\n4. Fine-tune DistilBERT\n5. Evaluate and save model","metadata":{}},{"id":"87f14873-03a7-473c-8507-04ca5b3292c6","cell_type":"code","source":"# Fix tokenizer parallelism issue\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:11.416782Z","iopub.execute_input":"2026-01-28T08:03:11.417477Z","iopub.status.idle":"2026-01-28T08:03:11.424387Z","shell.execute_reply.started":"2026-01-28T08:03:11.417449Z","shell.execute_reply":"2026-01-28T08:03:11.423758Z"}},"outputs":[],"execution_count":1},{"id":"8c5bf922","cell_type":"markdown","source":"## 1. Install Dependencies","metadata":{}},{"id":"84463eb0","cell_type":"code","source":"!pip install transformers datasets torch scikit-learn accelerate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:11.425894Z","iopub.execute_input":"2026-01-28T08:03:11.426195Z","iopub.status.idle":"2026-01-28T08:03:15.817182Z","shell.execute_reply.started":"2026-01-28T08:03:11.426173Z","shell.execute_reply":"2026-01-28T08:03:15.816231Z"}},"outputs":[],"execution_count":2},{"id":"a02ad4d8","cell_type":"markdown","source":"## 2. Import Libraries","metadata":{}},{"id":"e5762b64","cell_type":"code","source":"import json\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification,\n    TrainingArguments, \n    Trainer,\n    DataCollatorWithPadding\n)\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch\nprint(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:15.818546Z","iopub.execute_input":"2026-01-28T08:03:15.818812Z","iopub.status.idle":"2026-01-28T08:03:46.507763Z","shell.execute_reply.started":"2026-01-28T08:03:15.818784Z","shell.execute_reply":"2026-01-28T08:03:46.506971Z"}},"outputs":[{"name":"stderr","text":"2026-01-28 08:03:31.480291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769587411.677662      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769587411.737919      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769587412.242769      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587412.242809      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587412.242811      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587412.242814      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"id":"37ebb91f","cell_type":"markdown","source":"## 3. Load Training Data\n\n**Note:** Upload `train_data.json` and `val_data.json` to Colab/Kaggle before running this cell.\n\nIn Colab: Click folder icon ‚Üí Upload files\n\nIn Kaggle: Add files in the Input section","metadata":{}},{"id":"0b51f2c4","cell_type":"code","source":"# Load data\nwith open('/kaggle/input/customer-chatbot/train_data.json', 'r') as f:\n    train_data = json.load(f)\n\nwith open('/kaggle/input/customer-chatbot/val_data.json', 'r') as f:\n    val_data = json.load(f)\n\nprint(f\"Training examples: {len(train_data)}\")\nprint(f\"Validation examples: {len(val_data)}\")\nprint(f\"\\nSample: {train_data[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:46.508790Z","iopub.execute_input":"2026-01-28T08:03:46.509815Z","iopub.status.idle":"2026-01-28T08:03:46.548716Z","shell.execute_reply.started":"2026-01-28T08:03:46.509786Z","shell.execute_reply":"2026-01-28T08:03:46.547945Z"}},"outputs":[{"name":"stdout","text":"Training examples: 1315\nValidation examples: 329\n\nSample: {'text': 'i want exit', 'label': 'goodbye'}\n","output_type":"stream"}],"execution_count":4},{"id":"20b0c2e3","cell_type":"markdown","source":"## 4. Prepare Dataset","metadata":{}},{"id":"526b1fcd","cell_type":"code","source":"# Create label mapping\nunique_labels = sorted(list(set([item['label'] for item in train_data])))\nlabel2id = {label: idx for idx, label in enumerate(unique_labels)}\nid2label = {idx: label for label, idx in label2id.items()}\n\nprint(f\"Number of intents: {len(unique_labels)}\")\nprint(f\"Labels: {unique_labels}\")\n\n# Convert labels to IDs\nfor item in train_data:\n    item['labels'] = label2id[item['label']]\n\nfor item in val_data:\n    item['labels'] = label2id[item['label']]\n\n# Create Hugging Face datasets\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\n\nprint(f\"\\nDataset created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:46.550437Z","iopub.execute_input":"2026-01-28T08:03:46.550717Z","iopub.status.idle":"2026-01-28T08:03:46.570312Z","shell.execute_reply.started":"2026-01-28T08:03:46.550695Z","shell.execute_reply":"2026-01-28T08:03:46.569624Z"}},"outputs":[{"name":"stdout","text":"Number of intents: 10\nLabels: ['goodbye', 'greeting', 'hours', 'order_status', 'payment', 'pricing', 'product_info', 'return', 'support', 'thanks']\n\nDataset created successfully!\n","output_type":"stream"}],"execution_count":5},{"id":"e15c87a1","cell_type":"markdown","source":"## 5. Tokenize Data","metadata":{}},{"id":"bf9df5ce","cell_type":"code","source":"# Load tokenizer\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(examples['text'], truncation=True, padding=True, max_length=128)\n\n# Tokenize datasets\ntokenized_train = train_dataset.map(tokenize_function, batched=True)\ntokenized_val = val_dataset.map(tokenize_function, batched=True)\n\n# Remove unnecessary columns - keep only what the model needs\ntokenized_train = tokenized_train.remove_columns(['text', 'label'])\ntokenized_val = tokenized_val.remove_columns(['text', 'label'])\n\nprint(\"‚úÖ Tokenization complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:46.571189Z","iopub.execute_input":"2026-01-28T08:03:46.571431Z","iopub.status.idle":"2026-01-28T08:03:49.718433Z","shell.execute_reply.started":"2026-01-28T08:03:46.571409Z","shell.execute_reply":"2026-01-28T08:03:49.717705Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f8366f15ad942a5a213411947f56aad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b550438969d4679ad229fc8988f8e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f59d3e9731a8497e9d3e7f0088f14695"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e4630762884d1d9a9c7bcc0f9010d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1315 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22100d4f86fb4f2b9cd50247be800cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/329 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287d21a496104c6bb6e86cedefd1798c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Tokenization complete!\n","output_type":"stream"}],"execution_count":6},{"id":"4d045063","cell_type":"markdown","source":"## 6. Load Model","metadata":{}},{"id":"f5c0de5c","cell_type":"code","source":"# Load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=len(unique_labels),\n    id2label=id2label,\n    label2id=label2id\n)\n\nprint(f\"‚úÖ Model loaded: {model_name}\")\nprint(f\"üìä Parameters: {model.num_parameters():,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:49.719461Z","iopub.execute_input":"2026-01-28T08:03:49.719734Z","iopub.status.idle":"2026-01-28T08:03:53.732136Z","shell.execute_reply.started":"2026-01-28T08:03:49.719711Z","shell.execute_reply":"2026-01-28T08:03:53.731305Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"155167f743c04a67a146ac49bb5a0e4f"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Model loaded: distilbert-base-uncased\nüìä Parameters: 66,961,162\n","output_type":"stream"}],"execution_count":7},{"id":"5e2e2ef5","cell_type":"markdown","source":"## 7. Define Metrics","metadata":{}},{"id":"1e9f9112","cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    accuracy = accuracy_score(labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:53.733069Z","iopub.execute_input":"2026-01-28T08:03:53.733307Z","iopub.status.idle":"2026-01-28T08:03:53.737783Z","shell.execute_reply.started":"2026-01-28T08:03:53.733284Z","shell.execute_reply":"2026-01-28T08:03:53.737083Z"}},"outputs":[],"execution_count":8},{"id":"39f55cfa","cell_type":"markdown","source":"## 8. Training Arguments","metadata":{}},{"id":"ef158b90","cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./intent_classifier\",\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    push_to_hub=False,\n    logging_steps=10,\n    warmup_steps=100,\n    dataloader_num_workers=0,\n    report_to=\"none\",                    # ADD THIS LINE - disables wandb\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:53.738746Z","iopub.execute_input":"2026-01-28T08:03:53.739045Z","iopub.status.idle":"2026-01-28T08:03:54.057809Z","shell.execute_reply.started":"2026-01-28T08:03:53.738994Z","shell.execute_reply":"2026-01-28T08:03:54.057248Z"}},"outputs":[],"execution_count":9},{"id":"33005cfa-d03a-41a8-8785-02f63e274449","cell_type":"code","source":"# Check GPU memory before training\nimport subprocess\nresult = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\nprint(result.stdout.decode('utf-8'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:54.058698Z","iopub.execute_input":"2026-01-28T08:03:54.059001Z","iopub.status.idle":"2026-01-28T08:03:54.112386Z","shell.execute_reply.started":"2026-01-28T08:03:54.058970Z","shell.execute_reply":"2026-01-28T08:03:54.111475Z"}},"outputs":[{"name":"stdout","text":"Wed Jan 28 08:03:54 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0             31W /  250W |     257MiB /  16384MiB |      2%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n","output_type":"stream"}],"execution_count":10},{"id":"cc20ff3d","cell_type":"markdown","source":"## 9. Train Model","metadata":{}},{"id":"189b42ff","cell_type":"code","source":"\n# Create data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Create trainer with more verbosity\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# Train with progress tracking\nprint(\"üöÄ Starting training...\")\nprint(f\"Training samples: {len(tokenized_train)}\")\nprint(f\"Validation samples: {len(tokenized_val)}\")\nprint(f\"Starting epoch 1 of {training_args.num_train_epochs}...\")\n\ntrainer.train()\nprint(\"‚úÖ Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:03:54.113354Z","iopub.execute_input":"2026-01-28T08:03:54.113793Z","iopub.status.idle":"2026-01-28T08:04:08.787515Z","shell.execute_reply.started":"2026-01-28T08:03:54.113758Z","shell.execute_reply":"2026-01-28T08:04:08.786756Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting training...\nTraining samples: 1315\nValidation samples: 329\nStarting epoch 1 of 3...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/3793347754.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [495/495 00:13, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.073600</td>\n      <td>0.760674</td>\n      <td>0.960486</td>\n      <td>0.932007</td>\n      <td>0.960486</td>\n      <td>0.945001</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.079600</td>\n      <td>0.057082</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.045000</td>\n      <td>0.031201</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Training complete!\n","output_type":"stream"}],"execution_count":11},{"id":"8104426d","cell_type":"markdown","source":"## 10. Evaluate Model","metadata":{}},{"id":"6a4e2a4c","cell_type":"code","source":"# Evaluate\nresults = trainer.evaluate()\nprint(\"\\nüìä Evaluation Results:\")\nfor key, value in results.items():\n    print(f\"  {key}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:04:08.788387Z","iopub.execute_input":"2026-01-28T08:04:08.788674Z","iopub.status.idle":"2026-01-28T08:04:09.025031Z","shell.execute_reply.started":"2026-01-28T08:04:08.788646Z","shell.execute_reply":"2026-01-28T08:04:09.024380Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [42/42 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nüìä Evaluation Results:\n  eval_loss: 0.0571\n  eval_accuracy: 1.0000\n  eval_precision: 1.0000\n  eval_recall: 1.0000\n  eval_f1: 1.0000\n  eval_runtime: 0.2281\n  eval_samples_per_second: 1442.1900\n  eval_steps_per_second: 184.1090\n  epoch: 3.0000\n","output_type":"stream"}],"execution_count":12},{"id":"a08b114a","cell_type":"markdown","source":"## 11. Test Predictions","metadata":{}},{"id":"45c3bd1a","cell_type":"code","source":"# Test the model\ndef predict_intent(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n    predicted_class_id = predictions.argmax().item()\n    confidence = predictions[0][predicted_class_id].item()\n    \n    return id2label[predicted_class_id], confidence\n\n# Test examples\ntest_examples = [\n    \"Hello, how are you?\",\n    \"Where is my package?\",\n    \"How much does this cost?\",\n    \"I want to return my order\",\n    \"What products do you have?\"\n]\n\nprint(\"üß™ Testing predictions:\\n\")\nfor example in test_examples:\n    intent, confidence = predict_intent(example)\n    print(f\"Text: '{example}'\")\n    print(f\"  ‚Üí Intent: {intent} (confidence: {confidence:.2%})\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:04:09.025818Z","iopub.execute_input":"2026-01-28T08:04:09.026298Z","iopub.status.idle":"2026-01-28T08:04:09.066700Z","shell.execute_reply.started":"2026-01-28T08:04:09.026275Z","shell.execute_reply":"2026-01-28T08:04:09.065969Z"}},"outputs":[{"name":"stdout","text":"üß™ Testing predictions:\n\nText: 'Hello, how are you?'\n  ‚Üí Intent: greeting (confidence: 94.22%)\n\nText: 'Where is my package?'\n  ‚Üí Intent: order_status (confidence: 95.27%)\n\nText: 'How much does this cost?'\n  ‚Üí Intent: pricing (confidence: 94.89%)\n\nText: 'I want to return my order'\n  ‚Üí Intent: order_status (confidence: 81.71%)\n\nText: 'What products do you have?'\n  ‚Üí Intent: product_info (confidence: 94.93%)\n\n","output_type":"stream"}],"execution_count":13},{"id":"385aa67e","cell_type":"markdown","source":"## 12. Save Model","metadata":{}},{"id":"9d50fe06","cell_type":"code","source":"# Create a zip file of the trained model for download\nimport shutil\nfrom datetime import datetime\n\n# Ensure we're in the working directory where Kaggle can find outputs\nos.chdir('/kaggle/working')\n\n# Create zip file with timestamp\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nzip_filename = f\"intent_classifier_final_{timestamp}\"\nshutil.make_archive(zip_filename, 'zip', output_dir)\n\n# Verify the file exists\nzip_path = f\"{zip_filename}.zip\"\nif os.path.exists(zip_path):\n    size_mb = os.path.getsize(zip_path) / (1024*1024)\n    print(f\"‚úÖ Model zipped successfully: {zip_filename}.zip\")\n    print(f\"üì¶ Size: {size_mb:.2f} MB\")\n    print(f\"\\nüì• To download from Kaggle:\")\n    print(f\"   1. Click 'Output' tab in the right sidebar\")\n    print(f\"   2. Look for '{zip_filename}.zip'\")\n    print(f\"   3. Click download icon\")\n    print(f\"\\nüí° After download, extract to:\")\n    print(f\"   d:\\\\3224\\\\customer-service-chatbot\\\\models\\\\intent_classifier_final\\\\\")\nelse:\n    print(\"‚ùå Error: Zip file not created. Check permissions.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:07:43.902766Z","iopub.execute_input":"2026-01-28T08:07:43.903667Z","iopub.status.idle":"2026-01-28T08:07:57.323741Z","shell.execute_reply.started":"2026-01-28T08:07:43.903630Z","shell.execute_reply":"2026-01-28T08:07:57.323059Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Model zipped successfully: intent_classifier_final_20260128_080743.zip\nüì¶ Size: 235.88 MB\n\nüì• To download from Kaggle:\n   1. Click 'Output' tab in the right sidebar\n   2. Look for 'intent_classifier_final_20260128_080743.zip'\n   3. Click download icon\n\nüí° After download, extract to:\n   d:\\3224\\customer-service-chatbot\\models\\intent_classifier_final\\\n","output_type":"stream"}],"execution_count":16},{"id":"3e9bc7d1-3ba7-4b49-b92f-77cbb54cb88d","cell_type":"code","source":"# Alternative: Use Kaggle's download function\nfrom IPython.display import FileLink\n\n# Display clickable download link\nzip_path = f\"{zip_filename}.zip\"\ndisplay(FileLink(zip_path))\nprint(f\"üëÜ Click the link above to download directly!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T08:07:57.325049Z","iopub.execute_input":"2026-01-28T08:07:57.325355Z","iopub.status.idle":"2026-01-28T08:07:57.331677Z","shell.execute_reply.started":"2026-01-28T08:07:57.325332Z","shell.execute_reply":"2026-01-28T08:07:57.331086Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/intent_classifier_final_20260128_080743.zip","text/html":"<a href='intent_classifier_final_20260128_080743.zip' target='_blank'>intent_classifier_final_20260128_080743.zip</a><br>"},"metadata":{}},{"name":"stdout","text":"üëÜ Click the link above to download directly!\n","output_type":"stream"}],"execution_count":17}]}