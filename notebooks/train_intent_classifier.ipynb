{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6447a2e7",
   "metadata": {},
   "source": [
    "# Fine-tune Intent Classification Model\n",
    "## Customer Service Chatbot - Intent Classifier Training\n",
    "\n",
    "This notebook fine-tunes a DistilBERT model for intent classification.\n",
    "\n",
    "**Platform:** Google Colab or Kaggle\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Load training data\n",
    "3. Prepare dataset\n",
    "4. Fine-tune DistilBERT\n",
    "5. Evaluate and save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5bf922",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84463eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch scikit-learn accelerate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ad4d8",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5762b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebb91f",
   "metadata": {},
   "source": [
    "## 3. Load Training Data\n",
    "\n",
    "**Note:** Upload `train_data.json` and `val_data.json` to Colab/Kaggle before running this cell.\n",
    "\n",
    "In Colab: Click folder icon â†’ Upload files\n",
    "\n",
    "In Kaggle: Add files in the Input section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('train_data.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('val_data.json', 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "print(f\"Training examples: {len(train_data)}\")\n",
    "print(f\"Validation examples: {len(val_data)}\")\n",
    "print(f\"\\nSample: {train_data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b0c2e3",
   "metadata": {},
   "source": [
    "## 4. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping\n",
    "unique_labels = sorted(list(set([item['label'] for item in train_data])))\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Number of intents: {len(unique_labels)}\")\n",
    "print(f\"Labels: {unique_labels}\")\n",
    "\n",
    "# Convert labels to IDs\n",
    "for item in train_data:\n",
    "    item['labels'] = label2id[item['label']]\n",
    "\n",
    "for item in val_data:\n",
    "    item['labels'] = label2id[item['label']]\n",
    "\n",
    "# Create Hugging Face datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "\n",
    "print(f\"\\nDataset created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c87a1",
   "metadata": {},
   "source": [
    "## 5. Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9df5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"âœ… Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d045063",
   "metadata": {},
   "source": [
    "## 6. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model loaded: {model_name}\")\n",
    "print(f\"ðŸ“Š Parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e2ef5",
   "metadata": {},
   "source": [
    "## 7. Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f55cfa",
   "metadata": {},
   "source": [
    "## 8. Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef158b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./intent_classifier\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    logging_steps=10,\n",
    "    warmup_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20ff3d",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"ðŸš€ Starting training...\")\n",
    "trainer.train()\n",
    "print(\"âœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104426d",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nðŸ“Š Evaluation Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b114a",
   "metadata": {},
   "source": [
    "## 11. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def predict_intent(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_class_id = predictions.argmax().item()\n",
    "    confidence = predictions[0][predicted_class_id].item()\n",
    "    \n",
    "    return id2label[predicted_class_id], confidence\n",
    "\n",
    "# Test examples\n",
    "test_examples = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Where is my package?\",\n",
    "    \"How much does this cost?\",\n",
    "    \"I want to return my order\",\n",
    "    \"What products do you have?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ§ª Testing predictions:\\n\")\n",
    "for example in test_examples:\n",
    "    intent, confidence = predict_intent(example)\n",
    "    print(f\"Text: '{example}'\")\n",
    "    print(f\"  â†’ Intent: {intent} (confidence: {confidence:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385aa67e",
   "metadata": {},
   "source": [
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and tokenizer\n",
    "output_dir = \"./intent_classifier_final\"\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Save label mappings\n",
    "with open(f\"{output_dir}/label_mappings.json\", 'w') as f:\n",
    "    json.dump({\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Model saved to {output_dir}\")\n",
    "print(\"\\nðŸ“¦ Download these files to use in your Flask app:\")\n",
    "print(\"  - All files in intent_classifier_final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf15ab",
   "metadata": {},
   "source": [
    "## 13. Download Model (Colab only)\n",
    "\n",
    "Run this if you're on Google Colab to download the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the model directory\n",
    "!zip -r intent_classifier_final.zip intent_classifier_final/\n",
    "\n",
    "# Download (Colab only)\n",
    "from google.colab import files\n",
    "files.download('intent_classifier_final.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
